---
title: 'Tarea 4: regresión logística'
output:
  html_document:
    df_print: paged
---



En esta tarea construiremos varios modelos de regresión logística
y compararemos sus resultados.

### Preparación

Puedes usar el siguiente código, o tus implementaciones propias:

```{r}
source("tarea_4_codigo.R")
```

Usaremos los datos de sobrevivientes del hundimiento del Titanic,
obtenidos de [este concurso de Kaggle](https://www.kaggle.com/c/titanic)

```{r}
library(tidyverse)
datos_titanic <- read_csv("./tarea_4_datos/train.csv")
```

En este caso, queremos predecir la variable *Survived* en términos del resto.
Para simiplificar el ejericicio, 

 - solo usaremos alguna de las variables,
 - ignoramos datos faltantes en la variable edad

```{r}
datos_titanic <- datos_titanic %>% select(Survived, Pclass, Age, Sex, Embarked) %>%
    filter(!is.na(Age), !is.na(Embarked))
summary(datos_titanic)
head(datos_titanic)
```

La descripción de las variables es:

survival	Survival	0 = No, 1 = Yes
pclass	Ticket class	1 = 1st, 2 = 2nd, 3 = 3rd
sex	Sex	
Age	Age in years	
embarked	Port of Embarkation	C = Cherbourg, Q = Queenstown, S = Southampton

Convertimos las variables categóricas a numerícas creando indicadoras, como
sigue:

```{r}
datos <- datos_titanic %>% 
         mutate(female = as.numeric(Sex == "female"),
                southampton = as.numeric(Embarked == "S"),
                cherbourg = as.numeric(Embarked == "C")) %>%
        select(-Embarked, -Sex)
datos
```

Consierando cómo se ven estos datos, podemos usar una normalización simple
(puedes también hacerlo como lo hicimos en clase), de forma que todas las variables
estén aproximadamente en el rango 0 - 1 :

```{r}
datos$age_n <- datos$Age / 60
datos$pclass_n <-(datos$Pclass - 1) / 3
datos_trans <- datos %>% select(Survived, pclass_n, age_n, female, southampton, cherbourg)
datos_trans
```



Y finalmente, separa en entrenamiento y prueba de esta forma (como estamos
normalizando con cantidades fijas, no tenemos que normalizar por separado):

```{r}
set.seed(2850)
datos_trans <- datos_trans %>% 
    mutate(u = runif(nrow(datos_trans))) 
entrena <- datos_trans %>% filter(u <= 0.7) %>% select(-u)
prueba <- datos_trans %>% filter(u > 0.7) %>% select(-u)
```

```{r}
nrow(entrena)
nrow(prueba)
x_ent <- as.matrix(entrena %>% select(-Survived))
x_pr <- as.matrix(prueba %>% select(-Survived))
y_ent <- entrena$Survived
y_pr <- prueba$Survived
```


### Ejercicio A

1. Ajusta un modelo usando solo una variable (por ejemplo, el indicador si 
abordó en cherbourg). Ajusta el tamaño de paso y checa convergencia

```{r}
x_ent_1 <- x_ent[ , "cherbourg", drop = FALSE] # drop=false es para no convertir en vector
devianza_ent <- devianza_calc(x_ent_1, y_ent)
grad_ent <- grad_calc(x_ent_1, y_ent)
## termina esta línea
z <- descenso(n = 100, c(0,0), eta = 0.001, grad_ent)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
x_pr_1 <-  x_pr[ , "cherbourg", drop = FALSE]
devianza_pr <- devianza_calc(x_pr_1, y_pr)
devianza_pr(z[100,])
```

3. Para este modelo simple, calcula la probabilidad estimada por el modelo
de sobrevivir 
para una persona que embarcó en cherbourg y una que no:

```{r}
# Rellena:
# probabilidad sobrevivir si no embarcó en Cherbourg
h( sum(z[100,])  )
# probabilidad si embarcó  en Cherbourg
h( sum(z[100,1]) )
```


### Ejercicio B

Ahora utiliza todas las variables, y repite el ejercicio anterior:

1. Ajusta un modelo usando solo una variable (por ejemplo, el indicador si 
abordó en cherbourg). Ajusta el tamaño de paso y checa convergencia

```{r}
devianza_ent <- devianza_calc(x_ent, y_ent)
grad_ent <- grad_calc(x_ent, y_ent)
## termina esta línea
z <- descenso(n = 5000, rep(0, 6), eta = 0.001, grad_ent)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(x_pr, y_pr)
devianza_pr(z[100,])
```


3. Calcula la probabidad estimada de que un hombre con boleto de 3a clase, de 60 años,
que abordó en southampton sobreviva. Repite para una mujer con boleto de 1a clase, de 60
años, que abordó en southampton


```{r}
beta  <- z[1000,]
names(beta) <- c("Intercept", colnames(x_ent))
beta

prob <- h( beta[1] + beta[2]*(1-1)/2 + beta[3]*(20)/60 + beta[4]*1 + beta[5]*1 + beta[6]*0)
prob <- p_beta(x = c(1, (3-1)/2, 60/60, 0, 1, 0), beta)
prob
```


4. Grafica las probabilidades estimadas para alguien que subió en Southampton,
para todos los rangos de edad, hombres y mujeres, de las tres clases posibles. Puedes
empezar con el siguiente código:

```{r}
dat_calc <- expand.grid(list ( pclass_n = unique(x_ent[,"pclass_n"]),
                   age_n = unique(x_ent[, "age_n"]),
                   female = c(0,1),
                   southampton = 1,
                   cherbourg = 0))
mat_calc <- as.matrix(dat_calc)
## rellena aquí las betas que obtuviste
beta <- z[100,] ## ajusta tus betas
dat_calc$p_surv <- p_beta(mat_calc, beta)
ggplot(dat_calc, aes(x = age_n, y = p_surv, colour= pclass_n, group=pclass_n)) +
    facet_wrap(~female) + geom_line() + ylim(c(0, 1)) +
    labs(title = "Probabilidades superviviencia (Pasajeros de Southampton)")
```

¿Cuáles son las probabilidades más altas? ¿Cuáles son las más bajas?


5. ¿Cuál de los dos modelos anteriores (una sola variable, todas las variables)
se desempeña mejor? ¿Por qué?

6. Calcula el error de clasificación de prueba 

```{r}
beta <- z[1000, ]
prob_pr <- p_beta(x_pr, beta)
y_pred <- as.numeric(prob_pr > 0.5)
table(y_pred, y_pr)
mean(y_pred != y_pr)
```

### Ejercicio C

Ahora supondremos que tenemos algunas variables adicionales para incluir en el modelo.
En este ejercicio veremos qué sucede si estas variables **no** pueden ayudarnos
a predecir (las simulamos al azar)

Dada la escala de nuestras variables, podemos simular variables con valores entre 0 y 1

```{r}
set.seed(201)
p_ruido <- 50 # agregamos 50 variables sin información
n_ent <- nrow(x_ent)
n_pr <- nrow(x_pr)
mat_ent <- matrix(runif(n_ent * p_ruido), n_ent, p_ruido)
mat_pr <- matrix(runif(n_pr * p_ruido), n_pr, p_ruido)
head(mat_ent)
```

1. Ajusta un modelo usando todas las variables, incluyendo
las generadas aleatoriamente:

```{r}
devianza_ent <- devianza_calc(cbind(x_ent, mat_ent), y_ent)
grad_ent <- grad_calc(cbind(x_ent, mat_ent), y_ent)
## termina esta línea
z <- descenso(n = 1000, rep(0, 6 + p_ruido), eta = 0.0001, grad_ent)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(cbind(x_pr, mat_pr), y_pr)
devianza_pr(z[1000,])
```

Prueba utilizando otras semillas. Contesta:

- ¿Cómo es la devianza de prueba
de el modelo con las variables ruidosas en comparación al modelo con
las seis variables originales?
- ¿Podría ser que la devianza de prueba fuera un poco mejor para el modelo
ruidoso?¿Por qué sí o por qué no?
- ¿Cómo se compara la devianza de *entrenamiento* del modelo con 6 variables
con el modelo con todas las variables ruidosas?


3. Haz pruebas agregando 2 o 3 variables ruidosas. ¿Qué tan grande es la diferencia
entre la evaluación de los modelos?
