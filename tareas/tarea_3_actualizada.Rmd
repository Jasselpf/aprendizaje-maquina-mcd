---
title: "Tarea 3: clasificaci칩n y devianza"
author: "FG"
date: "8/28/2018"
output: html_document
---


### Instrucciones
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

En este ejercicio tienes que completar algunas l칤neas de c칩digo para 
contestar las preguntas

Consideramos los datos que vimos en clase, donde *diabetes* es la variable
indicadora si la persona tiene o no diabetes:

```{r}
library(tidyverse)
diabetes_ent <- as_data_frame(MASS::Pima.tr)
diabetes_pr <- as_data_frame(MASS::Pima.te)
datos_ent <- diabetes_ent %>% 
    mutate(diabetes = as.numeric(type == "Yes")) %>%
    select(diabetes, glu) 
set.seed(886)
# Usamos una muestra chica de prueba para examinar los resultados
datos_pr <- diabetes_pr %>% 
    mutate(diabetes = as.numeric(type == "Yes")) %>%
    select(diabetes, glu) %>%
    sample_n(10)
datos_ent
```

Trabajaremos con una muestra chica de prueba para entender los resultados:

```{r}
datos_pr <- datos_pr %>% arrange(glu)
datos_pr
```


### Preguntas

1. (Modelo sin covariables) Si no tuvi칠ramos covariables, 쯖칩mo estimamos la probabilidad de clase 
$$p_1 = P(G = 1),$$
donde G=diabetes? Usa la muestra de entrenamiento para hacer esta estimaci칩n.

Gr치fica de los datos
```{r}
library(ggplot2)
ggplot(datos_pr, aes(x=glu, y=diabetes, colour=diabetes)) +
           geom_point()
```


```{r}
# termina esta linea
p_1_simple <- mean(datos_ent$diabetes)
p_1_simple
```

2. Agregar la probabilidad estimada a la tabla de datos de prueba y examina la tabla:

```{r}
datos_pr$p_1_simple <- p_1_simple
datos_pr
```


2. **Calcula la devianza de prueba para cada caso** seg칰n el modelo
simple (el error de cada caso de prueba). Examina la tabla resultante:
```{r}
library(ggplot2)
f_1 <-function(x){
    g = 1
    -2*g*log(x)}
f_2 <-function(x){
    g = 0
    -2*(1-g)*log(1-x)}
ggplot(data_frame(x=0:1), aes(x = x))+stat_function(fun = f_1)+stat_function(fun = f_2)
```

```{r}
# explica por que esta es la formula correcta:
# El error, desvianza es mayor cuando el valor de g es cercano a cero, y la probabilidad estimada es grande o cercana a 1.
# El error, desvianza es mayor cuando el valor de g es cercano a uno, y la probabilidad estimada es peque침a o cercana a 0.
#Devianza o Cross Entrophy
devianza <- function(g, p_1){
     -2*(g * log(p_1) + (1 - g) * log(1 - p_1))
}
# termina esta linea
datos_pr$devianza_simple <- devianza(datos_pr$diabetes,p_1_simple)
datos_pr
```

3. **Calcula la devianza promedio** de prueba para este modelo simple:

```{r}
# termina esta linea
mean(datos_pr$devianza_simple)
```


4. Repite el inciso anterior usando el modelo $p_1=0.75$ (a cada quien se le asigna
probabilidad 1/2 de tener diabetes). **쮺u치l tiene menor devianza promedio de prueba?
Explica intuitivamente examinando las tablas que construiste.**

```{r}
# termina esta linea
datos_pr$devianza_simple_2 <- devianza(datos_pr$diabetes,0.75)
datos_pr
mean(datos_pr$devianza_simple_2)
```


5. Ahora construimos un modelo de una sola variable (glucosa) que no nos
va a servir. Intentamos
usaremos regresion lineal:

```{r}
ggplot(datos_ent, aes(x = glu, y = diabetes)) + 
    geom_jitter(width=0.1, height=0.1) + geom_smooth(se = FALSE, method = "lm")
```

**쯈ue defecto ves en este modelo? 쮼s posible calcular la devianza de este modelo?
쯇or que si o no?
#El problema son los valores estimados para glucosa por debajo de 75. No se puede obtener devianza, porque no se puede obtener logaritmo de valores negativos

Demuestra que este modelo simple no nos da probabilidades de clase evaluando
la prediccion en algun valor**:

```{r}
# escoge un valor problematico para este modelo problematico
valor_malo <- 60
#
mod_lineal <- lm(diabetes ~ glu, data = datos_ent)
predict(mod_lineal, data_frame(glu = valor_malo))
```

6. Consideremos una mejora usando k-vecinos mas cercanos:

```{r}
#install.packages("kknn")
library(kknn)
# escoge entre 50 o 60 k-vecinos m치s cercanos
k <- 60
#
graf_datos <- data_frame(glu = seq(50, 200))
mod_vmc <- kknn(diabetes ~ glu, k = k, train = datos_ent, 
              test = graf_datos)
graf_datos$p_1 <- mod_vmc$fitted.values
ggplot(graf_datos, aes(x = glu, y = p_1)) + geom_line() + ylim(c(0,1))
```

**Explica por qu칠 este modelo es m치s apropiado para este problema de clasificaci칩n**
쯅os da probabilidades?
Con este modelo si se obtienen probabilidades.

7. Agregar la probabilidad estimada segun el modelo del inciso anterior
a la misma tabla de datos de prueba. Examina la tabla:


```{r}
preds_vmc <- kknn(diabetes ~ glu, k = k, train = datos_ent, test = datos_pr)
datos_pr$p_1_vmc <- predict(preds_vmc)
datos_pr
```

Examinando la tabla, 쯣or que piensas que este nuevo modelo que usa una covariable
puede tener menor devianza? (examina la variable diabetes y la probabilidad p_1_vmc)

8. Calcula la devianza para cada caso de prueba seg칰n el modelo de vecinos m치s cercanos, 
y agrega a la tabla. 쮺칰ales son los errores m치s grandes y m치s chicos con este nuevo modelo?
Explica los casos de devianza grande.

```{r}
# termina la siguiente linea
datos_pr$devianza_vmc <- devianza(datos_pr$diabetes,datos_pr$p_1_vmc)
datos_pr
```

9. Calcula la devianza promedio de prueba para el modelo de vecinos mas cercanos

```{r}
# escribe aqui la l暗ea de c祚igo que calcula la devianza promedio 
mean(datos_pr$devianza_vmc)

```


10. Aunque la muestra de prueba es chica, 쯖ual es el mejor modelo segun la devianza
de prueba, el simple o el de vecinos mas cercanos? 
Vecinos mas cernaos
```{r}
dia_pr <- diabetes_pr %>% 
    mutate(diabetes = as.numeric(type == "Yes")) %>%
    select(diabetes, glu) %>%
    arrange(glu)
dia_pr
```

```{r}
preds_vmc_2 <- kknn(diabetes ~ glu, k = k, train = datos_ent, test = dia_pr)
dia_pr$p_1_vmc_2 <- predict(preds_vmc_2)
mean(dia_pr$p_1_vmc_2)
```


