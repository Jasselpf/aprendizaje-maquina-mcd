---
title: "Tarea 4: regresión logística"
output: html_notebook
---



En esta tarea construiremos varios modelos de regresión logística
y compararemos sus resultados.

### Preparación

Puedes usar el siguiente código, o tus implementaciones propias:

```{r}
source("tarea_4_codigo.R")
```

Revisa las funciones que están ahí. Son las que usamos en clase.

Usaremos los datos de sobrevivientes del hundimiento del Titanic,
obtenidos de [este concurso de Kaggle](https://www.kaggle.com/c/titanic)

```{r}
library(tidyverse)
datos_titanic <- read_csv("./tarea_4_datos/train.csv")
```

En este caso, queremos predecir la variable *Survived* en términos del resto.
Para simiplificar el ejericicio, 

 - solo usaremos algunas de las variables,
 - ignoramos datos faltantes en la variable edad

```{r}
datos_titanic <- datos_titanic %>% select(Survived, Pclass, Age, Sex, Embarked) %>%
    filter(!is.na(Age), !is.na(Embarked))
summary(datos_titanic)
head(datos_titanic)
```

La descripción de las variables es:

survival	Survival	0 = No, 1 = Yes
pclass	Ticket class	1 = 1st, 2 = 2nd, 3 = 3rd
sex	Sex	
Age	Age in years	
embarked	Port of Embarkation	C = Cherbourg, Q = Queenstown, S = Southampton

Convertimos las variables categóricas a numerícas creando indicadoras, como
sigue:

```{r}
datos <- datos_titanic %>% 
         mutate(female = as.numeric(Sex == "female"),
                southampton = as.numeric(Embarked == "S"),
                cherbourg = as.numeric(Embarked == "C")) %>%
        select(-Embarked, -Sex)
datos
```

Consierando cómo se ven estos datos, podemos usar una normalización simple
(puedes también hacerlo como lo hicimos en clase), de forma que todas las variables
estén aproximadamente en el rango 0 - 1 :

```{r}
datos$age_n <- datos$Age / 60
datos$pclass_n <-(datos$Pclass - 1) / 3
datos_trans <- datos %>% select(Survived, pclass_n, age_n, female, southampton, cherbourg)
datos_trans
```



Y finalmente, separa en entrenamiento y prueba de esta forma (como estamos
normalizando con cantidades fijas, no tenemos que normalizar por separado):

```{r}
set.seed(2850)
datos_trans <- datos_trans %>% 
    mutate(u = runif(nrow(datos_trans))) 
entrena <- datos_trans %>% filter(u <= 0.7) %>% select(-u)
prueba <- datos_trans %>% filter(u > 0.7) %>% select(-u)
```

```{r}
nrow(entrena)
nrow(prueba)
x_ent <- as.matrix(entrena %>% select(-Survived))
x_pr <- as.matrix(prueba %>% select(-Survived))
y_ent <- entrena$Survived
y_pr <- prueba$Survived
```


### Ejercicio A

1. Ajusta un modelo usando solo una variable (por ejemplo, el indicador si 
abordó en cherbourg). Ajusta el tamaño de paso y checa convergencia

```{r}
x_ent_1 <- x_ent[ , "cherbourg", drop = FALSE] # drop=false es para no convertir en vector
devianza_ent <- devianza_calc(x_ent_1, y_ent)
grad_ent <- grad_calc(x_ent_1, y_ent)

## termina esta línea para descenso en gradiente
z <- descenso(130,c(-0.2,0.2),0.005,grad_ent)
tail(z)
#grad_ent(0.2)

glm(Survived ~ cherbourg, data = entrena, family = "binomial" )
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
x_pr_1 <-  x_pr[ , "cherbourg", drop = FALSE]
devianza_pr <- devianza_calc(x_pr_1, y_pr)
# termina esta línea
devianza_ent(z[130,]) ## 667.5147 -- devianza de entrenamiento
devianza_ent(z[130,])/nrow(x_ent) ## 1.30374
devianza_pr(z[130,]) ## 266.9904 -- devianza de prueba
devianza_pr(z[130,])/nrow(x_pr) ## 1.334952
```

3. Para este modelo simple, calcula la probabilidad estimada por el modelo
de sobrevivir para una persona que embarcó en cherbourg y una que no:

```{r}
# Rellena:
# probabilidad sobrevivir si no embarcó en Cherbourg
p_beta(0,z[130,])
# probabilidad si embarcó  en Cherbourg
p_beta(1,z[130,])
```

4. Curva ROC

```{r}
library(ROCR)
mod_1 <- glm(Survived ~ cherbourg, entrena, family = "binomial")
#mod_1
prueba$probs_prueba_1 <- predict(mod_1, newdata = prueba, type = "response") 
#tail(x_pr)

pred_rocr <- prediction(prueba$probs_prueba_1, prueba$Survived) 
perf <- performance(pred_rocr, measure = "sens", x.measure = "fpr") 
graf_roc_1 <- data_frame(tfp = perf@x.values[[1]], sens = perf@y.values[[1]], 
                       d = perf@alpha.values[[1]])

ggplot(graf_roc_1, aes(x = tfp, y = sens, colour=d)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 

auc_1 <- performance(pred_rocr, measure = 'auc')@y.values
auc_1 #0.5456115
```



### Ejercicio B

Ahora utiliza todas las variables, y repite el ejercicio anterior:

1. Ajusta un modelo usando solo una variable (por ejemplo, el indicador si 
abordó en cherbourg). Ajusta el tamaño de paso y checa convergencia

```{r}
devianza_ent <- devianza_calc(x_ent, y_ent)
grad_ent <- grad_calc(x_ent, y_ent)
## termina esta línea
z <- descenso(500,c(0.2,-2,-1,0.2,0.2,0.2),0.003,grad_ent)
colnames(z) <- colnames(entrena)
tail(z)
#matplot(z)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(x_pr, y_pr)
devianza_pr(z[500,] ) ## 155.7327 -- devianza de prueba (6 variables)
devianza_pr(z[500,])/nrow(x_pr) ## 0.7786637 (6 variables)
devianza_ent(z[500,]) ## 488.6215 -- devianza entrenamiento (6 variables)
devianza_ent(z[500,])/nrow(x_ent) ## 0.9543389 --devianza entrenamiento (6 variables)
```


3. Calcula la probabidad estimada de que un hombre con boleto de 3a clase, de 60 años,
que abordó en southampton sobreviva. Repite para una mujer con boleto de 1a clase, de 60
años, que abordó en southampton

```{r}
x_h_1 <- cbind(0,1,0,1,0)
x_h_2 <- cbind(1/3,1,0,1,0)
x_h_3 <- cbind(2/3,1,0,1,0)
x_m <- cbind(0,1,1,1,0)
p_beta(x_h_1,z[500,])
p_beta(x_h_2,z[500,])
p_beta(x_h_3,z[500,])
p_beta(x_m,z[500,])
```


4. Grafica las probabilidades estimadas para alguien que subió en Southampton,
para todos los rangos de edad, hombres y mujeres, de las tres clases posibles. Puedes
empezar con el siguiente código:

```{r}
# vamos a calcular proabilidades para estos datos
dat_calc <- expand.grid(list ( pclass_n = unique(x_ent[,"pclass_n"]),
                   age_n = unique(x_ent[, "age_n"]),
                   female = c(0,1),
                   southampton = 1,
                   cherbourg = 0))
mat_calc <- as.matrix(dat_calc)
## rellena aquí las betas que obtuviste
beta <- z[500,]
# calcula las probabilidades (puedes usar la fucnión p_beta, por ejemplo)
dat_calc$p_surv <- p_beta(mat_calc,beta)
ggplot(dat_calc, aes(x = age_n, y = p_surv, colour= pclass_n, group=pclass_n)) +
    facet_wrap(~female) + geom_line() + ylim(c(0, 1)) +
    labs(title = "Probabilidades superviviencia (Pasajeros de Southampton)")
```

¿Cuáles son las probabilidades más altas? ¿Cuáles son las más bajas?
# Las probabilidades de supervivencia más altas corresponden a mujeres de primera clase


5. ¿Cuál de los dos modelos anteriores (una sola variable, todas las variables)
se desempeña mejor? ¿Por qué?
# Varias variables, la devianza es menor


6. Calcula el error de clasificación de prueba 
```{r}
#p_beta(x_pr,z[500,])
prueba$p_est <- p_beta(x_pr,z[500,])
prueba <- prueba %>% 
          mutate(Survived_est = ifelse(prueba$p_est <= 0.5,0,1))
prueba <- prueba %>%
          mutate(err_clas = ifelse(prueba$Survived == prueba$Survived_est,0,1))
mean(prueba$err_clas)
```


7. Curva ROC

```{r}
library(ROCR)
mod_2 <- glm(Survived ~ pclass_n + age_n +female + southampton + cherbourg, entrena, 
             family = "binomial")

prueba$probs_prueba_2 <- predict(mod_2, newdata = prueba, type = "response") 

pred_rocr_2 <- prediction(prueba$probs_prueba_2, prueba$Survived) 
perf_2 <- performance(pred_rocr_2, measure = "sens", x.measure = "fpr") 
graf_roc_2 <- data_frame(tfp = perf_2@x.values[[1]], sens = perf_2@y.values[[1]], 
                       d = perf_2@alpha.values[[1]])

ggplot(graf_roc_2, aes(x = tfp, y = sens, colour=d)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 

auc_2 <- performance(pred_rocr_2, measure = 'auc')@y.values
auc_2 #0.9053248
```

### Ejercicio C

Ahora supondremos que tenemos algunas variables adicionales para incluir en el modelo.
En este ejercicio veremos qué sucede si estas variables **no** pueden ayudarnos
a predecir (las simulamos al azar)

Dada la escala de nuestras variables, podemos simular variables con valores entre 0 y 1

```{r}
set.seed(201)
p_ruido <- 50 # agregamos 50 variables sin información
n_ent <- nrow(x_ent)
n_pr <- nrow(x_pr)
mat_ent <- matrix(runif(n_ent * p_ruido), n_ent, p_ruido)
mat_pr <- matrix(runif(n_pr * p_ruido), n_pr, p_ruido)
#head(mat_ent)
```

1. Ajusta un modelo usando todas las variables, incluyendo
las generadas aleatoriamente:

```{r}
devianza_ent <- devianza_calc(cbind(x_ent, mat_ent), y_ent)
grad_ent <- grad_calc(cbind(x_ent, mat_ent), y_ent)
## termina esta línea
set.seed(300)
z_ini <- c(0,-2,-2,1,2,0.2,runif(50,0,1))
z <- descenso(600,z_ini,0.0001,grad_ent)
tail(z)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(cbind(x_pr, mat_pr), y_pr)
devianza_pr(z[600,]) ##165.3291
devianza_pr(z[600,])/nrow(x_pr) ##0.8266454 (50 variables) vs ## 0.7786637 (6 variables)
devianza_ent(z[600,]) ## 461.8003
devianza_ent(z[600,])/nrow(x_ent) ## 0.9019537 
```

Prueba utilizando otras semillas. Contesta:

- ¿Cómo es la devianza de prueba
de el modelo con las variables ruidosas en comparación al modelo con
las seis variables originales?
# La devianza de prueba es mayor para el modelo de 50 variables ruidosas
# Al principio las variables no estaban convergiendo, y obtenía una devianza mucho mayor,
después reduje el tamaño del salto a 0.001 y la desvianza era solo un poco mayor a la devianza con las 6 variables


- ¿Podría ser que la devianza de prueba fuera un poco mejor para el modelo
ruidoso?¿Por qué sí o por qué no?



- ¿Cómo se compara la devianza de *entrenamiento* del modelo con 6 variables
con el modelo con todas las variables ruidosas?
# el error de entrenamiento es comparable (3 variables vs 50 variables), el modelo más pequeño está contenido en el modelo de minimización de 50 variables
```{r}
devianza_ent(z[600,]) # 461.8003 -- 50 variables ruidosas
devianza_ent(z[600,])/nrow(x_ent) ## 0.9019537 -- 50 variables ruidosas 
## 0.9543389 --devianza entrenamiento (6 variables)
```

##Ejercicio 4
1. Haz pruebas agregando 2 o 3 variables ruidosas. ¿Qué tan grande es la diferencia
entre la evaluación de los modelos?

```{r}
set.seed(100)
p_ruido <- 3 # agregamos 3 variables sin información
n_ent <- nrow(x_ent)
n_pr <- nrow(x_pr)
mat_ent <- matrix(runif(n_ent * p_ruido), n_ent, p_ruido)
mat_pr <- matrix(runif(n_pr * p_ruido), n_pr, p_ruido)
#head(mat_ent)
```

2. Ajusta un modelo usando todas las variables, incluyendo
las generadas aleatoriamente:

```{r}
devianza_ent <- devianza_calc(cbind(x_ent, mat_ent), y_ent)
grad_ent <- grad_calc(cbind(x_ent, mat_ent), y_ent)
## termina esta línea
set.seed(300)
z_ini <- c(0,-2,-2,1,2,0.2,runif(3,0,1))
z <- descenso(600,z_ini,0.0001,grad_ent)
z[590:600,]
```


```{r}
devianza_pr <- devianza_calc(cbind(x_pr, mat_pr), y_pr)
devianza_pr(z[600,]) ##159.9205 --devianza 3 variables ruidosas
devianza_pr(z[600,])/nrow(x_pr) ##0.7996024 (3 variables) vs ## 0.7786637 (6 variables)
devianza_ent(z[600,]) ## 491.6203
devianza_ent(z[600,])/nrow(x_ent) ## 0.9601959 (3 variables) vs  
## 0.9543389 --devianza entrenamiento (6 variables)
```

3. Curva ROC

```{r}
library(ROCR)

#entrena <- cbind(entrena,mat_ent)
#colnames(entrena) <- c("Survived","pclass_n","age_n","female","southampton","cherbourg","V1","V2","V3")

#prueba <- cbind(prueba,mat_pr)
#colnames(prueba) <- cbind("Survived","pclass_n","age_n","female","southampton","cherbourg","probs_prueba_1","p_est","Survived_est","err_clas","probs_prueba_2","V1","V2","V3")

mod_3 <- glm(Survived ~ pclass_n+age_n+female+southampton+cherbourg+V1+V2+V3, entrena, 
             family = "binomial")

prueba$probs_prueba_3 <- predict(mod_3, newdata = prueba, type = "response") 

pred_rocr_3 <- prediction(prueba$probs_prueba_3, prueba$Survived) 
perf_3 <- performance(pred_rocr_3, measure = "sens", x.measure = "fpr") 
graf_roc_3 <- data_frame(tfp = perf_3@x.values[[1]], sens = perf_3@y.values[[1]], 
                       d = perf_3@alpha.values[[1]])

ggplot(graf_roc_3, aes(x = tfp, y = sens, colour=d)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 

auc_3 <- performance(pred_rocr_3, measure = 'auc')@y.values
auc_3 #0.9069986
```

```{r}
graf_roc_1$modelo <- 'Solo glucosa'
graf_roc_2$modelo <- 'Todas las variables'
graf_roc_3$modelo <- 'Todas las variables + 3(ruido)'

graf_roc <- bind_rows(graf_roc_1, graf_roc_2, graf_roc_3)

ggplot(graf_roc, aes(x = tfp, y = sens, colour = modelo)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 
```



