# Regresion logistica {#logistica}

```{r, include = FALSE}
library(tidyverse)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_minimal())
```

## El problema de clasificacion

Una variabla $G$ **categorica** o **cualitativa** toma valores que no
son numÈricos. Por ejemplo, si $G$ denota el estado del contrato de celular
de un cliente dentro de un aÒo, podrÌamos tener $G\in \{ activo, cancelado\}$.

En un **problema de clasificaciÛn** buscamos predecir una variable respuesta
categ√≥rica $G$ en funci√≥n de otras variables de entrada
$X=(X_1,X_2,\ldots, X_p)$.

#### Ejemplos {-}
- Predecir si un cliente cae en impago de una tarjeta de cr√©dito, de forma
que podemos tener $G=corriente$ o $G=impago$. Variables de entrada podr√≠an
ser $X_1=$ porcentaje de saldo usado, $X_2=$ atrasos en los √∫lltimos 3 meses,
$X_3=$ edad, etc

- En nuestro ejemplo de 
reconocimiento de d√≠gitos tenemos $G\in\{ 0,1,\ldots, 9\}$. N√≥tese
que los` d√≠gitos no se pueden considerar como valores num√©ricos (son etiquetas).
Tenemos que las entradas $X_j$ para $j=1,2,\ldots, 256$ son valores de cada pixel
(im√°genes blanco y negro).

- En reconocimiento de im√°genes quiza tenemos que $G$ pertenece a un conjunto
que t√≠picamente contiene miles de valores (manzana, √°rbol, pluma, perro, coche, persona,
cara, etc.). Las $X_j$ son valores de pixeles de la imagen para tres canales
(rojo, verde y azul). Si las im·genes son de 100x100, tendr√≠amos 30,000 variables
de entrada.


### ¬øQu√© estimar en problemas de clasificaci√≥n? {-}


En problemas de regresi√≥n, consideramos modelos de la forma $Y= f(X) + \epsilon$,
y vimos que pod√≠amos plantear el problema de aprendizaje supervisado como uno 
donde el objetivo
es estimar lo mejor que podamos la funci√≥n $f$ mediante un estimador
$\hat{f}$. Usamos entonces $\hat{f}$ para hacer predicci√≥nes. En el caso de regresi√≥n:
  
- $f(X)$ es la relaci√≥n sistem√°tica de $Y$ en funci√≥n de $X$
- Dada $X$, la variable observada $Y$ es una variable aleatoria
  ($\epsilon$ depende de otras variables que no conocemos)

No podemos usar un modelo as√≠
en clasificaci√≥n pues $G$ no es num√©rica. Sin embargo, podemos pensar que $X$
nos da cierta informaci√≥n probabil√≠stica acerca de las clases que pueden ocurrir:
  
- $P(G|X)$ es la probabilidad condicional de observar $G$ si tenemos $X$. Esto es la informaci√≥n sistem√°tica de $G$ en funci√≥n de $X$
- Dada $X$, la clase observada $G$ es una variable aleatoria 
(depende de otras variables que no conocemos).

En analog√≠a con el problema de regresi√≥n, quisi√©ramos estimar las probabilidades condicionales $P(G|X)$, que es la parte sistem√°tica de la relaci√≥n de $G$ en funci√≥n de $X$.

Normalmente codificamos las clases $g$ con una etiqueta num√©rica, de modo
que $G\in\{1,2,\ldots, K\}$:


#### Ejemplo {-}
(Impago de tarjetas de cr√©dito) 
Supongamos que $X=$ porcentaje del cr√©dito m√°ximo usado, y $G\in\{1, 2\}$, donde
$1$ corresponde al corriente y $2$ representa impago. Podr√≠amos tener, por ejemplo:

\begin{align*} 
p_1(10\%) &= P(G=1|X=10\%) = 0.95 \\
p_2(10\%) &= P(G=2|X=10\%) =  0.05
\end{align*}

y 

\begin{align*} 
p_1(95\%) &= P(G=1|X=95\%) = 0.70 \\
p_2(95\%) &= P(G=2|X=95\%) =  0.30
\end{align*}


En resumen:

```{block2, type='comentario'}
En problemas de clasificaci√≥n queremos estimar la parte
sistem√°tica de la relaci√≥n de $G$ en funci√≥n $X$, que en este caso quiere
decir que buscamos estimar las probabilidades condicionales:
\begin{align*}
p_1(x) &= P(G=1|X=x), \\
p_2(x) &= P(G=2|X=x), \\
\vdots &  \\
p_K(x) &= P(G=K|X=x)
\end{align*}
 para cada valor $x$ de las entradas.
```

A partir de estas probabilidades de clase podemos producir un clasificador de 
varias maneras (las discutiremos m√°s adelante). La
forma m√°s simple es usando el clasificador de Bayes:


```{block2, type = 'comentario'}
Dadas las probabilidades condicionales $p_1(x),p_2(x),\ldots, p_K(x)$, el 
**clasificador de Bayes** asociado est√° dado por
$$G (x) = \arg\max_{g} p_g(x)$$

Es decir, clasificamos en la clase que tiene m√°xima probabilidad de ocurrir.
```





#### Ejemplo {-}
(Impago de tarjetas de cr√©dito) 
Supongamos que $X=$ porcentaje del cr√©dito m√°ximo usado, y $G\in\{1, 2\}$, donde
$1$ corresponde al corriente y $2$ representa impago.
 Las probabilidades condicionales de clase para la clase *al corriente* podr√≠an
 ser, por ejemplo:

- $p_1(x) = P(G=1|X = x) =0.95$  si $x < 15\%$
- $p_1(x) = P(G=1|X = x) = 0.95 - 0.007(x-15)$ si $x>=15\%$
  
Estas son probabilidades, pues hay otras variables que influyen en que un cliente
permanezca al corriente o no en sus pagos m√°s all√° de informaci√≥n contenida en el
porcentaje de cr√©dito usado. N√≥tese que estas probabilidades son diferentes
a las no condicionadas, por ejempo, podr√≠amos tener que a total $P(G=1)=0.83$.

```{r, fig.width = 5, fig.asp = 0.7 }
p_1 <- function(x){
  ifelse(x < 15, 0.95, 0.95 - 0.007 * (x - 15))
}
ggplot(data_frame(x = 0:100), aes(x = x)) + stat_function(fun = p_1) 
```

¬øPor qu√© en este ejemplo ya no mostramos la funci√≥n $p_2(x)$? 

Si usamos el clasificador de Bayes, tendr√≠amos por ejemplo que
si $X=10\%$, como $p_1(10\%) = 0.95$ y $p_2(10\%)=0.05$, nuestra predicci√≥n
de clase ser√≠a $G(10\%) = 1$ (al corriente), pero si $X=70\%$,
$G(70\%) = 1$ (impago), pues $p_1(70\%) = 0.57$ y $p_2(70\%) = 0.43$.



## Estimaci√≥n de probabilidades de clase

¬øC√≥mo estimamos ahora las probabilidades de clase a partir de una
muestra de entrenamiento? Veremos por ahora
dos m√©todos: k-vecinos m√°s cercanos y regresi√≥n log√≠stica. 




### Ejemplo {-}


Vamos a generar unos datos con el modelo simple del ejemplo anterior:

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(kknn) # para hacer vecinos m√°s cercanos
simular_impago <- function(n = 500){
    # suponemos que los valores de x est√°n concentrados en valores bajos,
    # quiza la manera en que los creditos son otorgados
    x <- pmin(rexp(n, 1 / 40), 100)
    # las probabilidades de estar al corriente:
    probs <- p_1(x)
    # finalmente, simulamos cu√°les clientes siguen en al corriente y cuales no:
    g <- ifelse(rbinom(length(x), 1, probs) == 1 ,1, 2)
    dat_ent <- data_frame(x = x, p_1 = probs, g = factor(g))
    dat_ent
}
set.seed(1933)
dat_ent  <- simular_impago() %>% select(x, g) 
dat_ent %>% sample_n(20)
```

Como este problema es de dos clases, podemos graficar como sigue:

```{r, fig.width = 5, fig.asp = 0.7}
graf_1 <- ggplot(dat_ent, aes(x = x)) +
  geom_point(aes(colour = g, y = as.numeric(g=='1')))
graf_1
```

Esta gr√°fica tiene el problema de que hay mucho trasplape entre los puntos.
Podemos agregar variaci√≥n artificial alrededor de 1 y 0, y tambi√©n 
alrededor de los valores de $x$ para evitar traslape en los extremos:

```{r, fig.width = 5, fig.asp = 0.7}
graf_1 <- ggplot(dat_ent, aes(x = x)) +
  geom_jitter(aes(colour = factor(g), y = as.numeric(g=='1')), width=0.5, height=0.05)
graf_1 
```



### k-vecinos m√°s cercanos 

Podemos extender f√°cilmente k vecinos m√°s cercanos para ver un ejemplo de c√≥mo
estimar
las probabilidades de clase $p_g(x)$. La idea general es igual que en regresi√≥n,
y es simple: nos fijamos en las tasas locales de impago alrededor de la $x$ para
la que queremos predecir.

Supongamos entonces que tenemos un conjunto de entrenamiento
$${\mathcal L}=\{ (x^{(1)},g^{(1)}),(x^{(2)},g^{(2)}), \ldots, (x^{(N)}, g^{(N)}) \}$$

La idea es que si queremos predecir en $x_0$, busquemos varios $k$ vecinos m√°s cercanos
a $x_0$, y estimamos entonces $p_g(x)$ como la **proporci√≥n** de casos tipo $g$ que
hay entre los $k$ vecinos de $x_0$. 

Vemos entonces que este m√©todo es un intento de hacer una aproximaci√≥n directa
de las probabilidades condicionales de clase.

Podemos escribir esto como:


```{block, type='comentario'}
**k vecinos m√°s cercanos para clasificaci√≥n**

Estimamos contando los elementos de cada clase entre los $k$ vecinos m√°s cercanos:
$$\hat{p}_g (x_0) = \frac{1}{k}\sum_{x^{(i)} \in N_k(x_0)} I( g^{(i)} = g),$$
    
    
para $g=1,2,\ldots, K$,  donde $N_k(x_0)$ es el conjunto de $k$ vecinos m√°s cercanos en ${\mathcal L}$
de $x_0$, y $I(g^{(i)}=g)=1$ cuando $g^{(i)}=g$, y cero en otro caso (indicadora).
```




#### Ejemplo {-}

Regresamos a nuestro problema de impago. Vamos a intentar estimar la
probabilidad condicional de estar al corriente usando k vecinos 
m√°s cercanos (curva roja):



```{r,fig.width = 5, fig.asp = 0.7}
graf_data <- data_frame(x = seq(0,100, 1))
vmc <- kknn(g ~ x, train = dat_ent,  k = 60,
              test = graf_data)
graf_data$p_1 <- vmc$prob[ ,1]
graf_verdadero <- data_frame(x = 0:100, p_1 = p_1(x))
graf_1 + 
  geom_line(data = graf_data, aes(y = p_1), colour = 'red', size=1.2) +
  geom_line(data = graf_verdadero, aes(y = p_1)) +
  ylab('Probabilidad al corriente') + xlab('% cr√©dito usado') 
```

Igual que en el caso de regresi√≥n, ahora tenemos qu√© pensar c√≥mo validar nuestra
estimaci√≥n, pues no vamos a tener la curva negra real para comparar.

```{block, type='comentario'}
Arriba denotamos las probabilidades te√≥ricas como
$p_1 (x), p_2 (x), \ldots, p_K (x)$. Denotamos probabilidades estimadas
como $\hat{p}_1 (x), \hat{p}_2 (x), \ldots, \hat{p}_K (x)$
```

### Ejemplo {-}
Consideremos datos de diabetes en mujeres Pima:

A population of women who were at least 21 years old, of Pima Indian heritage and living near Phoenix, Arizona, was tested for diabetes according to World Health Organization criteria. The data were collected by the US National Institute of Diabetes and Digestive and Kidney Diseases. We used the 532 complete records after dropping the (mainly missing) data on serum insulin.

- npreg number of pregnancies.
- glu plasma glucose concentration in an oral glucose tolerance test.
- bp diastolic blood pressure (mm Hg).
- skin triceps skin fold thickness (mm).
- bmi body mass index (weight in kg/(height in m)\^2).
- ped diabetes pedigree function.
- age age in years.
- type Yes or No, for diabetic according to WHO criteria.

```{r, message=FALSE, warning=FALSE}
diabetes_ent <- as_data_frame(MASS::Pima.tr)
diabetes_pr <- as_data_frame(MASS::Pima.te)
diabetes_ent
```

Intentaremos predecir diabetes dependiendo del BMI:

```{r, fig.width=5, fig.asp=0.7}
library(ggplot2)
ggplot(diabetes_ent, aes(x = bmi, y= as.numeric(type=='Yes'), colour = type)) +
  geom_point()
```

Usamos $20$ vecinos mas cercanos para estimar $p_g(x)$:


```{r, fig.width=5, fig.asp=0.7}
graf_data <- data_frame(bmi = seq(20,45, 1))
vmc_5 <- kknn(type ~ bmi, train = diabetes_ent,  k = 20,
              test = graf_data, kernel = 'rectangular')
graf_data$Yes <- vmc_5$prob[ ,"Yes"]
graf_data$No <- vmc_5$prob[ ,"No"]
graf_data <- graf_data %>% gather(type, prob, Yes:No)
ggplot(diabetes_ent, aes(x = bmi, y= as.numeric(type=='Yes'), colour = type)) +
  geom_point() + 
  geom_line(data = filter(graf_data, type =='Yes') , 
            aes(x=bmi, y = prob, colour=type, group = type)) +
  ylab('Probabilidad diabetes')
```



## Error para modelos de clasificacion

En regresi√≥n, vimos que la p√©rdida cuadr√°tica era una buena opci√≥n para ajustar
modelos (descenso en gradiente, por ejemplo), y tambi√©n para evaluar su desempe√±o.
Ahora necesitamos una p√©rdida apropiada para trabajar con modelos de clasificaci√≥n.

Consideremos entonces que tenemos una estimaci√≥n $\hat{p}_g(x)$ de las probabilidad
de clase $P(G=g|X=x)$. Supongamos que observamos ahora $(x, g)$. 

- Si 
$\hat{p}_{g}(x)$ es muy cercana a uno, deber√≠amos penalizar poco, pues dimos
probabilidad alta a $G=g$.
- Si $\hat{p}_{g}(x)$ es chica, deber√≠amos penalizar m√°s, pues dimos probabilidad baja
a $G=g$.
- Si $\hat{p}_{g}(x)$ es muy cercana a cero, y observamos $G=g$, deber√≠amos hacer
una penalizaci√≥n muy alta (convergiendo a $\infty$, pues no es aceptable que sucedan
eventos con probabilidad estimada extremadamente baja).



Quisi√©ramos encontrar una funci√≥n $h$ apropiada, de forma que la p√©rdida
al observar $(x, g)$ sea 
$$s(\hat{p}_{g}(x)),$$
y que cumpla con los puntos arriba se√±alados. Entonces tenemos que

- $s$ debe ser una funci√≥n continua y decreciente en $[0,1]$
- Podemos poner $s(1)=0$ (no hay p√©rdida si ocurre algo con probabilidad 1)
- $s(p)$ debe ser muy grande is $p$ es muy chica.

Una opci√≥n anal√≠ticamente conveniente es
$$s(p) = - 2log(p)$$

```{r, fig.width=5, fig.asp=0.7}
s <- function(z){ -2*log(z)}
ggplot(data_frame(p = (0:100)/100), aes(x = p)) + 
    stat_function(fun = s) + ylab("Devianza")
```


Y entonces la p√©rdida (que llamamos **devianza**) que construimos est√° dada, para
$(x,g)$ observado y probabilidades estimadas $\hat{p}_g(x)$ por

$$
- 2\log(\hat{p}_g(x))
$$

Su valor esperado (seg√∫n el proceso que genera los datos) es nuestra medici√≥n
del desempe√±o del modelo $\hat{p}_g (x)$, es decir, el error de predicci√≥n es:

$$-2E\left [ \log(\hat{p}_G(X)) \right ]$$

que podemos estimar con una muestra de prueba.

**Observaciones**:

- Ojo: el nombre de devianza se utiliza
de manera diferente en distintos lugares (pero para cosas similares). 

- Usamos el factor 2 por razones hist√≥ricas (la medida de devianza
definida en estad√≠stica tiene un 2, para usar m√°s f√°cilmente en 
pruebas de hip√≥tesis relacionadas con comparaciones de modelos). Para nuestros
prop√≥sitos, podemos usar o no el 2.

- No es f√°cil interpretar la devianza, pero es √∫til para comparar modelos. Veremos
otras medidas m√°s f√°ciles de intrepretar m√°s adelante.


Compara la siguiente definici√≥n con la que vimos para modelos de regresi√≥n:

```{block2, type = 'comentario'}
Sea $${\mathcal L}=\{ (x^{(1)},g^{(1)}),(x^{(2)},g^{(2)}), \ldots, (x^{(N)}, g^{(N)}) \}$$
una muestra de entrenamiento, a partir de las cuales construimos mediante
un algoritmo  funciones estimadas
$\hat{p}_{g} (x)$ para $g=1,2,\ldots, K$. La **devianza promedio de entrenamiento** 
est√° dada por
\begin{equation}
\overline{err} = - \frac{2}{N}\sum_{i=1}^N log(\hat{p}_{g^{(i)}} (x^{(i)}))
  (\#eq:devianza)
\end {equation}

Sea $${\mathcal T}=\{ (x_0^{(1)},g_0^{(1)}),(x_0^{(2)},g_0^{(2)}), \ldots, (x_0^{(m)}, g_0^{(m)}) \}$$ una muestra de prueba. La **devianza promedio de prueba** es
\begin{equation}
\hat{Err} = - \frac{2}{m}\sum_{i=1}^m log(\hat{p}_{g_0^{(i)}} (x_0^{(i)}))
\end {equation}
que es una estimaci√≥n de la devianza de predicci√≥n
$$-2E\left [ \log(\hat{p}_G(X)) \right ]$$
```


#### Ejemplo {-}

Regresamos a nuestros ejemplo simulado de impago de tarjetas de cr√©dito. Primero
calculamos la devianza de entrenamiento

```{r}
s <- function(x) -2*log(x)
vmc_entrena <- kknn(g ~ x, train = dat_ent,  k = 60,
              test = dat_ent, kernel = 'rectangular')
dat_dev <- dat_ent %>% select(x,g)
dat_dev$hat_p_1 <- predict(vmc_entrena, type ='prob')[,1]
dat_dev$hat_p_2 <- predict(vmc_entrena, type ='prob')[,2]
dat_dev <- dat_dev %>% mutate(hat_p_g = ifelse(g==1, hat_p_1, hat_p_2))
```

N√≥tese que dependiendo de qu√© clase observamos (columna $g$), extraemos la
probabilidad correspondiente a la columna hat_p_g:

```{r}
set.seed(125)
dat_dev %>% sample_n(20)
```

Ahora aplicamos la funci√≥n $s$ que describimos arriba, y promediamos sobre
el conjunto de entrenamiento:

```{r}
dat_dev <- dat_dev %>% mutate(dev = s(hat_p_g))
dat_dev %>% ungroup %>% summarise(dev_entrena = mean(dev))
```

Recordemos que la devianza de entrenamiento no es la cantidad que eval√∫a el
desempe√±o del modelo. Hagamos el c√°lculo entonces para una muestra de prueba:

```{r}
set.seed(1213)
dat_prueba <- simular_impago(n = 1000) %>% select(x, g)
vmc_prueba <- kknn(g ~ x, train = dat_ent,  k = 60,
              test = dat_prueba, kernel = 'rectangular')
dat_dev_prueba <- dat_prueba %>% select(x,g)
dat_dev_prueba$hat_p_1 <- predict(vmc_prueba, type ='prob')[,1]
dat_dev_prueba$hat_p_2 <- predict(vmc_prueba, type ='prob')[,2]
dat_dev_prueba <- dat_dev_prueba %>% mutate(hat_p_g = ifelse(g==1, hat_p_1, hat_p_2))
dat_dev_prueba <- dat_dev_prueba %>% mutate(dev = s(hat_p_g))
dat_dev_prueba %>% ungroup %>% summarise(dev_prueba = mean(dev))
```


### Ejercicio
Utiliza 5, 20, 60, 200 y 400 vecinos m√°s cercanos para nuestro ejemplo de tarjetas
de cr√©dito. ¬øCu√°l tiene menor devianza de prueba? ¬øCu√°l tiene menor devianza
de entrenamiento? Grafica el mejor que obtengas y otros dos modelos malos. ¬øPor qu√©
crees que la devianza es muy grande para los modelos malos? 

Nota: ten cuidado con probabilidades iguales a 0 o 1, pues en en estos casos
la devianza puede dar $\infty$. Puedes por ejemplo hacer que las probabilidades
siempre est√©n en $[\epsilon, 1-\epsilon]$ para $\epsilon>0$ chica.





### Error de clasificaciÛn y funciÛn de pÈrdida 0-1

Otra  medida com˙n para medir el error de un clasificador es
el *error de clasificaci√≥n*, que tambi√©n llamamos *probabilidad de clasificaci√≥n
incorrecta*, o error bajo p√©rdida 0-1. 

```{block2, type ='comentario'}
Si $\hat{G}$ es un clasificador (que puede
ser construido a partir de probabilidades de clase),
decimos que su **error de clasificacion** es

$$P(\hat{G}\neq G)$$

```

Aunque esta definici√≥n aplica para cualquier clasificador, podemos usarlo
para clasificadores construidos con probabilidades de clase de la siguiente
forma:

```{block2, type='comentario'}
Sean $\hat{p}_g(x)$ probabilidades de clase estimadas. El clasificador asociado
est√° dado por
$$\hat{G} (x) = \arg\max_g \hat{p}_g(x)$$
Podemos estimar su  error de clasificaci√≥n $P(\hat{G} \neq G)$ con una muestra
de prueba
$${\mathcal T}=\{ (x_0^{(1)},g_0^{(1)}),(x_0^{(2)},g_0^{(2)}), \ldots, (x_0^{(m)}, g_0^{(m)})$$
mediante
$$\hat{Err} = \frac{1}{m} \sum_{j=i}^m I(\hat{G}(x_0^{(i)}) \neq g_0^{(i)}),$$
es decir, la proporci√≥n de casos de prueba que son clasificados incorrectamente.
```

#### Ejemplo {-}
Veamos c√≥mo se comporta en t√©rminos de error de clasificaci√≥n nuestro √∫ltimo modelo:

```{r}
dat_dev$hat_G <- predict(vmc_entrena)
dat_dev %>% mutate(correcto = hat_G == g) %>% 
  ungroup %>% summarise(p_correctos = mean(correcto)) %>%
  mutate(error_clasif = 1 - p_correctos)
```

Y calculamos el error de clasificaci√≥n de prueba:

```{r}
dat_dev_prueba$hat_G <- predict(vmc_prueba)
dat_dev_prueba %>% mutate(correcto = hat_G == g) %>% 
  ungroup %>% summarise(p_correctos = mean(correcto)) %>%
  mutate(error_clasif = 1 - p_correctos)
```

### Discusi√≥n: relaci√≥n entre devianza y error de clasificaci√≥n

Cuando utilizamos devianza,
el mejor desempe√±o se alcanza cuando las probabilidades $\hat{p}_g (x)$
est√°n bien calibradas, es decir, est√°n cercanas a las probabilidades 
verdaderas $p_g (x)$. Esto se puede ver demostrando que las probabilidades
$\hat{p}_g (x)$ que minimizan la devianza 
$$-2E(\log (\hat{p}_G (X))) = -2E_X \left[  \sum_{g=1}^K p_g(X)\log\hat{p}_g(X)    \right]$$

son precisamente $\hat{p}_g (x)=p_g (x)$. 

Por otro lado, si consideramos el error de clasificaci√≥n $P(\hat{G}\neq G)$,
es posible demostrar que se minimiza cuando
$\hat{G} = G_{bayes}$, donde

$${G}_{bayes} (x) = \arg\max_g {p}_g(x).$$

En consecuencia, cuando las $\hat{p}_g(x)$ estimadas est√°n cercanas 
a las verdaderas $p_g (x)$ (que es lo que intentamos hacer cuando usamos devianza),
el clasificador $\hat{G}(x)$ producido a partir de las $\hat{p}_g(x)$ deber√°
estar cercano a $G_{bayes}(x)$, que es el clasificador que minimiza el error
de clasificaci√≥n.

Este argumento explica que buscar modelos con devianza baja est√° alineado
con buscar modelos con error de clasificaci√≥n bajo.

Cuando sea posible, es mejor trabajar con probabilidades de clase y devianza que solamente
con clasificadores y error de clasificaci√≥n. Hay varias razones para esto:

- Tenemos una medida de qu√© tan seguros estamos en la clasificaci√≥n (por ejemplo,
$p_1 = 0.55$ en vez de $p_1 = 0.995$). 
- La salida de probabilides es un insumo m√°s √∫til para tareas posteriores (por ejemplo,
si quisi√©ramos ofrecer las 3 clases m√°s probables en clasificaci√≥n de im√°genes).
- Permite hacer selecci√≥n de modelos de manera m√°s atinada: por ejemplo, dada una
misma tasa de correctos, preferimos aquellos modelos que lo hacen con probabilidades
que discriminan m√°s (m√°s altas cuando est√° en lo correcto y m√°s bajas cuando 
se equivoca).



## Regresi√≥n log√≠stica

En $k$ vecinos m√°s cercanos, intentamos estimar directamente con promedios
las probabilidades de clase, sin considerar ninguna estructura. 
Regresi√≥n log√≠stica (y otros m√©todos, como redes neuronales),
son ajustados intentando minimizar la devianza de entrenamiento. Esto es necesario
si queremos aprovechar la estructura adicional que estos modelos aportan.
En el caso de regresion log√≠stica, establecemos una estructura lineal de cierto tipo.
Recordemos
el caso de regresi√≥n lineal: intentamos minimizar el error de entrenamiento para
estimar nuestro predictor, y as√≠ pod√≠amos explotar apropiadamente
la estructura lineal del problema.


Regresi√≥n log√≠stica es un m√©todo lineal de clasificaci√≥n, en el sentido de
que produce fronteras lineales de decisi√≥n para el clasificador asociado.

#### Ejemplo {-}
Mostramos aqu√≠ una frontera de decisi√≥n de regresi√≥n log√≠stica y una de
k vecinos m√°s cercanos:
```{r, out.width= 350}
knitr::include_graphics(path = c("figuras/clas_lineal.png", "figuras/clas_nolineal.png"))
```


### RegresiÛn logÌstica simple

Vamos a construir el modelo de regresiÛn logÌstica (binaria) 
para una sola entrada. Suponemos que tenemos una sola entrada $X_1$, y que $G\in\{1,2\}$. 
Nos convendr· crear una nueva variable $Y$ dada por
$Y=1$ si $G=2$, $Y=0$ si $G=1$. 

NÛtese que intentar estimar las probabilidades de clase $p_1(x)$ de forma lineal con

$$p_1(x)=\beta_0+\beta_1 x_1$$
tiene el defecto de que el lado derecho puede producir valores fuera
de $[0,1]$. La idea es entonces aplicar una funciÛn $h$ simple
que transforme la recta real al intervalo $[0,1]:$
$$p_1(x) = h(\beta_0+\beta_1 x_1),$$
donde $h$ es una funciÛn que toma valores en $[0,1]$. øC˙al es la funciÛn
m·s simple que hace esto?

### FunciÛn logÌstica
 Comenzamos con el caso m·s simple, poniendo
$\beta_0=0$ y $\beta_1=1$, de modo que
$$p_1(x)=h(x).$$
¬øC√≥mo debe ser $h$ para garantizar que $h(x)$ est√° entre 0 y 1 para toda $x$?
No van a funcionar polinomios, por ejemplo, porque para un polinomio cuando
$x$ tiende a infinito, el polinomio tiende a $\infty$ o a $-\infty$.
Hay varias posibilidades, pero una de las m√°s simples es tomar (ver gr√°fica
al margen):

```{block2, type='comentario'}
La funciÛn logÌstica est· dada por
$$h(x)=\frac{e^x}{1+e^x}$$
``` 
NOTE: El calsificador de Bayes minimisa el error de clasificaciÛn
```{r}
h <- function(x){exp(x)/(1+exp(x)) }
ggplot(data_frame(x = seq(-6, 6, 0.01)), aes(x = x)) + stat_function(fun = h)
```


Esta funcion comprime adecuadamente (para nuestros propÛsitos) 
el rango de todos los reales dentro del intervalo $[0,1]$. Si aplicamos
al predictor lineal que consideramos, obtenemos:


```{block2, type='comentario'}
El modelo de regresiÛn logÌstica simple est· dado por
$$p_1(x)=p_1(x;\beta)= h(\beta_0+\beta_1x_1)= \frac{e^{\beta_0+\beta_1x_1}}{1+ e^{\beta_0+\beta_1x_1}},$$
y $$p_0(x)=p_0(x;\beta)=1-p_1(x;\beta),$$
donde $\beta=(\beta_0,\beta_1)$.
```

Este es un modelo paramÈtrico con 2 par·metros.

#### Ejercicio {-}

- Demostrar que, si $p_1(x)$ est· dado como en la ecuaciÛn anterior, entonces
tambiÈn podemos escribir:
$$p_0(x)=\frac{1}{1+e^{\beta_0+\beta_1x_1}}.$$

- Graficar las funciones $p_1(x;\beta)$ para distintos
valores de $\beta_0$ y $\beta_1$.

#### Ejemplo {-}
En nuestro ejemplo, tenÌamos el siguiente ajuste con k-vecinos m·s cercanos:

```{r, fig.width = 5, fig.asp = 0.7}
graf_data <- data_frame(x = seq(0,100, 1))
vmc_graf <- kknn(g ~ x, train = dat_ent,  k = 60,
              test = graf_data, kernel = 'rectangular')
graf_data$p_1 <- vmc_graf$prob[ ,1]
graf_verdadero <- data_frame(x = 0:100, p_1 = p_1(x))
graf_1 + 
    geom_line(data = graf_data, aes(y = p_1), colour = 'red', size=1.2) +
    geom_line(data = graf_verdadero, aes(y = p_1)) +
    ylab('Probabilidad al corriente') + xlab('% crÈdito usado')
```

Ahora intentaremos ajustar a mano (intenta cambiar
las betas para p_mod_1 y p_mod_2 en el ejemplo de abajo) 
algunos modelos logÌsticos para las probabilidades
de clase:

```{r, fig.width = 5, fig.asp = 0.7}
h <- function(z) exp(z)/(1+exp(z))
p_logistico <- function(beta_0, beta_1){
  p <- function(x){
    z <- beta_0 + beta_1*x
    h(z)
  }
}
p_mod_1 <- p_logistico(-20, 0.5)
p_mod_2 <- p_logistico(3, -0.04)
graf_data <- graf_data %>% 
  mutate(p_mod_1 = p_mod_1(x), p_mod_2 = p_mod_2(x))
graf_1 + 
  geom_line(data = graf_data, aes(y = p_mod_2), colour = 'red', size=1.2) +
    geom_line(data = graf_data, aes(y = p_mod_1), colour = 'orange', size=1.2) +
  geom_line(data = graf_verdadero, aes(y = p_1)) +
  ylab('Probabilidad al corriente') + xlab('% crÈdito usado')
```

Podemos usar tambiÈn la funciÛn glm de R para ajustar los coeficientes:

```{r}
mod_1 <- glm(g==1 ~ x, data = dat_ent, family = 'binomial')
coef(mod_1)
p_mod_final <- p_logistico(coef(mod_1)[1], coef(mod_1)[2])
graf_data <- graf_data %>% 
  mutate(p_mod_f = p_mod_final(x))

graf_1 + 
  geom_line(data = graf_data, aes(y = p_mod_f), colour = 'red', size = 1.2) +
  geom_line(data = graf_data, aes(y = p_mod_1), colour = 'orange', size = 1.2) +
  geom_line(data = graf_verdadero, aes(y = p_1)) +
  ylab('Probabilidad al corriente') + xlab('% cr√©dito usado')
```


### Regresi√≥n log√≠stica

Ahora escribimos el modelo cuando tenemos m√°s de una entrada. La idea es la misma:
primero combinamos las variables linealmente usando pesos $\beta$, y desp√∫es
comprimimos a $[0,1]$ usando la funci√≥n log√≠stica:

```{block2, type='comentario'}
El modelo de regresiÛn logÌstica est· dado por
$$p_1(x)=p_1(x;\beta)= h(\beta_0+\beta_1x_1 + \beta_2x_2 +\cdots + \beta_p x_p),$$
y $$p_0(x)=p_0(x;\beta)=1-p_1(x;\beta),$$
donde $\beta=(\beta_0,\beta_1, \ldots, \beta_p)$.
```

## Aprendizaje de coeficientes para regresiÛn logÌstica (binomial).


Ahora veremos c√≥mo aprender los coeficientes con una muestra de entrenamiento. La idea
general es :

- Usamos la devianza de entrenamiento como medida de ajuste
- Usamos descenso en gradiente para minimizar esta devianza y aprender los coeficientes.


Sea entonces ${\mathcal L}$ una muestra de entrenamiento:

$${\mathcal L}=\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \ldots, (x^{(N)}, y^{(N)}) \}$$

Donde $y=1$ o $y=0$ son las dos clases. Escribimos tambi√©n


$$p_1(x)=p_1(x;\beta)= h(\beta_0+\beta_1x_1 + \beta_2x_2 +\cdots + \beta_p x_p),$$

y definimos la devianza sobre el conjunto de entrenamiento

$$D(\beta) = -2\sum_{i=1}^N \log(p_{y^{(i)}} (x^{(i)})).$$ 

Los **coeficientes estimados por regresi√≥n log√≠stica** est√°n dados por
$$\hat{\beta} = \arg\min_\beta D(\beta)$$

Para minimizar utilizaremos descenso en gradiente (aunque hay m√°s opciones).

La √∫ltima expresi√≥n para $D(\beta)$ puede ser dif√≠cil de operar, pero podemos reescribir como:
$$D(\beta) = -2\sum_{i=1}^N y^{(i)} \log(p_{1} (x^{(i)})) + (1-y^{(i)}) \log(p_{0} (x^{(i)})).$$ 


Para hacer descenso en gradiente, necesitamos encontrar $\frac{\partial D}{\beta_j}$
para $j=1,2,\ldots,p$.

Igual que en regresiÛn lineal, comenzamos por calcular la derivada de un tÈrmino:

$$D^{(i)} (\beta) = y^{(i)} \log(p_{1} (x^{(i)})) + (1-y^{(i)}) \log(1-p_{1} (x^{(i)}))$$


Calculamos primero las derivadas de $p_1 (x^{(i)};\beta)$ (demostrar la siguiente ecuaciÛn):
$$\frac{\partial  p_1}{\partial \beta_0} = {p_1(x^{(i)})(1-p_1(x^{(i)}))},$$
y 
$$\frac{\partial  p_1}{\partial \beta_j} = p_1(x^{(i)})(1-p_1(x^{(i)}))x_j^{(i)},$$

AsÌ que
\begin{align*}
\frac{\partial D^{(i)}}{\partial \beta_j} &= \frac{y^{(i)}}{(p_1(x^{(i)}))}\frac{\partial  p_1}{\partial \beta_j} -
\frac{1- y^{(i)}}{(1-p_1(x^{(i)}))}\frac{\partial  p_1}{\partial \beta_j} \\
 &= \left( \frac{y^{(i)} - p_1(x^{(i)})}{(p_1(x^{(i)}))(1-p_1(x^{(i)}))}  \right )\frac{\partial  p_1}{\partial \beta_j} \\
 & = \left ( y^{(i)} - p_1(x^{(i)}) \right ) x_j^{(i)} \\ 
\end{align*}

para $j=0,1,\ldots,p$, usando la convenciÛn de $x_0^{(i)}=1$. Podemos sumar
ahora sobre la muestra de entrenamiento para obtener


$$ \frac{\partial D}{\partial\beta_j} = - 2\sum_{i=1}^N  (y^{(i)}-p(x^{(i)}))x_j^{(i)}$$

De modo que, 

```{block2, type='comentario'}
Para un paso $\eta>0$ fijo, la iteraci√≥n de descenso para regresi√≥n log√≠stica para
el coeficiente $\beta_j$ es:
$$\beta_{j}^{(k+1)} = \beta_j^{(k)} + {2\eta} \sum_{i=1}^N (y^{(i)}-p(x^{(i)}))x_j^{(i)}$$
para 
$j=0,1,\ldots, p$, donde fijamos $x_0^{(i)}=1$.
```


PodrÌamos usar las siguientes implementaciones, que representan cambios
menores de lo que hicimos en regresi√≥n lineal. En primer lugar,
escribimos la funci√≥n que calcula la devianza. Podr√≠amos poner:

```{r}
devianza_calc_simple <- function(x, y){
  dev_fun <- function(beta){
    p_beta <- h(as.matrix(cbind(1, x)) %*% beta) 
   -2*sum(y*log(p_beta) + (1-y)*log(1-p_beta))
  }
  dev_fun
}
```


***ObservaciÛn** 
Sin embargo, podemos hacer una simplificaciÛn para tener mejor desempeÒo y estabilidad.
Observamos que 
$$\log (p_1(x;\beta)) = \log\frac{ e^{x^t \beta}}{1+ e^{x^t\beta}} =
x^t\beta - \log Z$$

donde $Z = 1+ e^{x^t\beta}$. Por otra parte
$$\log(p_0(x;\beta)) = \log\frac{ 1}{1+ e^{x^t\beta}} = - \log Z$$
De modo que 
$$y\log(p_1(x;\beta)) + (1- y)\log(p_0(x;\beta)) = yx^t\beta - \log Z= yx^t\beta - \log (1+e^{x^t\beta})$$

AsÌ que podemos escribir:

```{r}
devianza_calc <- function(x, y){
  dev_fun <- function(beta){
    x_beta <- as.matrix(cbind(1, x)) %*% beta
   -2*sum(y*x_beta - log(1 + exp(x_beta)))
  }
  dev_fun
}
```

```{r}
grad_calc <- function(x_ent, y_ent){
  salida_grad <- function(beta){
    p_beta <- h(as.matrix(cbind(1, x_ent)) %*% beta) 
    e <- y_ent - p_beta
    grad_out <- -2*as.numeric(t(cbind(1,x_ent)) %*% e)
    names(grad_out) <- c('Intercept', colnames(x_ent))
    grad_out
  }
  salida_grad
}
descenso <- function(n, z_0, eta, h_deriv){
  z <- matrix(0,n, length(z_0))
  z[1, ] <- z_0
  for(i in 1:(n-1)){
    z[i+1, ] <- z[i, ] - eta * h_deriv(z[i, ])
  }
  z
}
```

#### Ejemplo {-}
Probemos nuestros c·lculos con el ejemplo de 1 entrada de tarjetas de crÈdito.

```{r}
dat_ent$y <- as.numeric(dat_ent$g==1)
dat_ent <- dat_ent %>% ungroup %>% mutate(x_s = (x - mean(x))/sd(x))
devianza <- devianza_calc_simple(dat_ent[, 'x_s', drop = FALSE], dat_ent$y)
grad <- grad_calc(dat_ent[, 'x_s', drop = FALSE], dat_ent$y)
grad(c(0,1))
grad(c(0.5,-0.1))
```
Verificamos c·lculo de gradiente:
```{r}
(devianza(c(0.5+0.0001,-0.1)) - devianza(c(0.5,-0.1)))/0.0001
(devianza(c(0.5,-0.1+0.0001)) - devianza(c(0.5,-0.1)))/0.0001
```
Y hacemos descenso:
```{r, fig.width=5, fig.asp=0.8}
iteraciones <- descenso(200, z_0 = c(0,0), eta = 0.001, h_deriv = grad)
tail(iteraciones, 20)
#Checamos devianza
plot(apply(iteraciones, 1, devianza))
# Y gradiente de devianza en la iteraci√≥n final:
grad(iteraciones[nrow(iteraciones), ])
```

Comparamos con glm:
NOTE: glm utiliza Newton Rapson para llegar al mÌnimo, segundas derivadas.
Para pocas varialibles se utiliza glm, es m·s r·pido 
```{r}
mod_1 <- glm(y~x_s, data=dat_ent, family = 'binomial') 
coef(mod_1)
mod_1$deviance
devianza(iteraciones[200,])
```

NÛtese que esta devianza est· calculada sin dividirentre el n˙mero de casos. Podemos calcular la devianza promedio de entrenamiento haciendo:

```{r}
devianza(iteraciones[200,])/nrow(dat_ent)
```

Estar en su media ~ evaluar h(beta_0)

NOTE: Revisar el libreo de 
RegresiÛn - Gelman, Hill

log odds logit 

#### M·xima verosimilitud {-}

Es f·cil ver que este mÈtodo de estimaciÛn de los coeficientes (minimizando la
devianza de entrenamiento) es el mÈtodo de m·xima verosimilitud.  La verosimilitud
de la muestra de entrenamiento est· dada por:

 $$L(\beta) =\prod_{i=1}^N p_{y^{(i)}} (x^{(i)})$$
Y la log verosimilitud es

 $$l(\beta) =\sum_{i=1}^N \log(p_{y^{(i)}} (x^{(i)})).$$

AsÌ que ajustar el modelo minimizando la expresiÛn
\@ref(eq:devianza)
es los mismo que hacer m√°xima verosimilitud (condicional a los valores de $x$).



#### NormalizaciÛn {-}
Igual que en regresiÛn lineal, en regresiÛn logÌstica conviene normalizar
las entradas antes de ajustar el modelo

#### DesempeÒo de regresiÛn logÌstica como mÈtodo de aprendizaje {-}
Igual que en regresiÛn lineal, regresiÛn logÌstica supera a mÈtodos
m·s sofisticados o nuevos en numerosos ejemplos. Las razones son similares:
la rigidez de regresi√≥n log√≠stica es una fortaleza cuando la estructura
lineal es una buena aproximaci√≥n.

#### SoluciÛn analÌtica
El problema de regresi√≥n log√≠stica no tiene soluci√≥n anal√≠tica. Paquetes
como *glm* utilizan m√©todos num√©ricos (Newton-Raphson para regresi√≥n log√≠stica,
por ejemplo).

#### Interpretaci√≥n de modelos log√≠sticos
**Todas** las precauciones que mencionamos en modelos lineales aplican
para los modelos log√≠sticos (aspectos estad√≠sticos del ajuste, 
relaci√≥n con fen√≥meno de inter√©s, argumentos
de causalidad). 

Igual que en regresi√≥n lineal, podemos explicar el comportamiento de las
probabilidades de clase ajustadas, pero es un poco m√°s dif√≠cil por la 
no linealidad introducida por la funci√≥n log√≠stica.


#### Ejemplo {-}

Consideremos el modelo ajustado:

```{r}
head(dat_ent)
coeficientes <- iteraciones[200,]
names(coeficientes) <- c("Intercept", "x_s")
coeficientes
```
Como centramos todas las entradas, la ordenada al origen (*Intercept*) se interpreta
como la probabilidad de clase cuando todas las variables est√°n en su media:
```{r}
options(digits = 2)
coeficientes[1]
h(coeficientes[1])
```

Esto quiere decir que la probabilidad de estar al corriente es de 87\% cuando
la variable $x$ est√° en su media.

Si $x$ se incrementa en una desviaci√≥n est√°ndar, la cantidad
$$z = \beta_0 + \beta_1x$$
 la probabilidad de estar al corriente cambia a 67\%:
```{r}
h(coeficientes[1]+ coeficientes[2]*1)
```

N√≥tese que una desviaci√≥n est√°ndar de $x$ equivale a

```{r}
sd(dat_ent$x)
```

As√≠ que en las unidades originales, un incremento de 30 en la variable $x$
implica un cambio de 

```{r}
h(coeficientes[1] + coeficientes[2]) - h(coeficientes[1])
```

es decir, la probabilidad de manenterse al corriente baja 19 puntos porcentuales,
de 85\% a 67%

**Ojo**: En regresiÛn lineal, las variables contribuyen independientemente
de otras al predictor. Eso no pasa en regresiÛn logÌstica debido a la no linealidad
introducida por la funciÛn logÌstica $h$. Por ejemplo, imaginemos el modelo:

$$p(z) = h(0.5 + 0.2 x_1 -0.5 x_2 + 0.7x_3),$$
y suponemos las entradas normalizadas.
Si todas las variables est·n en su media, la probabilidad de clase 1 es
```{r}
h(0.5)
```

Si todas las variables est√°n en su media, y cambiamos en 1 desviaci√≥n est√°ndar la
variable $x_1$, la probabilidad de clase 1 es:
```{r}
h(0.5+0.2)
```

Y el cambio en puntos de probabilidad es:
```{r}
h(0.5+0.2) - h(0.5)

```

Pero si la variable $x_2 = -1$, por ejemplo, el cambio en probabilidad es de
```{r}
h(0.5+ 0.2 + 0.5*1) - h(0.5 + 0.5*1)
```


## Ejercicio: datos de diabetes

Ya est·n divididos los datos en entrenamiento y prueba

```{r, message=FALSE, warning=FALSE}
diabetes_ent <- as_data_frame(MASS::Pima.tr)
diabetes_pr <- as_data_frame(MASS::Pima.te)
diabetes_ent
diabetes_ent$id <- 1:nrow(diabetes_ent)
diabetes_pr$id <- 1:nrow(diabetes_pr)
```

Normalizamos

```{r, message=FALSE, warning=FALSE }
library(dplyr)
library(tidyr)
datos_norm <- diabetes_ent %>% 
  gather(variable, valor, npreg:age) %>%
  group_by(variable) %>%
  summarise(media = mean(valor), de = sd(valor))

normalizar <- function(datos, datos_norm){
  datos %>% 
    gather(variable, valor, npreg:age) %>%
    left_join(datos_norm) %>%
    mutate(valor_s = (valor  - media)/de) %>%
    select(id, type, variable, valor_s) %>%
    spread(variable, valor_s)
}

diabetes_ent_s <- normalizar(diabetes_ent, datos_norm)
diabetes_pr_s <- normalizar(diabetes_pr, datos_norm)
```

```{r}
x_ent <- diabetes_ent_s %>% select(age:skin) %>% as.matrix
p <- ncol(x_ent)
y_ent <- diabetes_ent_s$type == 'Yes'
grad <- grad_calc(x_ent, y_ent)
iteraciones <- descenso(1000, rep(0,p+1), 0.001, h_deriv = grad)
matplot(iteraciones)
```

```{r}
diabetes_coef <- data_frame(variable = c('Intercept',colnames(x_ent)), coef = iteraciones[1000,])
diabetes_coef
```

Ahora calculamos devianza de prueba y error de clasificaciÛn:

```{r}
x_prueba <- diabetes_pr_s %>% select(age:skin) %>% as.matrix
y_prueba <- diabetes_pr_s$type == 'Yes'
dev_prueba <- devianza_calc(x_prueba, y_prueba)
dev_prueba(iteraciones[1000,])/nrow(x_prueba)
```

Y para el error clasificaci√≥n de prueba, necesitamos las probabilidades de clase ajustadas:
```{r}
beta <- iteraciones[1000, ]
p_beta <- h(as.matrix(cbind(1, x_prueba)) %*% beta) 
y_pred <- as.numeric(p_beta > 0.5)
mean(y_prueba != y_pred)
```

### Tarea {-}

La tarea est√° en *tareas/tarea_3_actualizada.Rmd*. (Nota: la versi√≥n anterior la 
dejaremos para m√°s tarde. Si ya resolvieron la versi√≥n anterior no hay problema. 
Si tienen dudas pueden escribirme a felipexgonzalez at gmail dot com).

